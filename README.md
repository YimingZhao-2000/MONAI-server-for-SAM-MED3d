---

# ğŸ§  MONAI Label åº”ç”¨é›†æˆæ–‡æ¡£ â€” æ¨ç†/è®­ç»ƒæ¨¡å—å¼€å‘æŒ‡å—

æœ¬æŒ‡å—ç”¨äºå¸®åŠ©ä½ åœ¨ `MONAI Label` æ¡†æ¶ä¸­è‡ªå®šä¹‰äº¤äº’å¼æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ DeepEdit / SAMMed3Dï¼‰ï¼Œä»¥æ”¯æŒ 3D åŒ»å­¦å›¾åƒçš„é«˜æ•ˆäº¤äº’åˆ†å‰²ã€‚

---

## ğŸ“ ç›®å½•ç»“æ„ï¼ˆæœ€ä½å¯è¿è¡Œç¤ºä¾‹ï¼‰

```bash
my_app/
â”‚
â”œâ”€â”€ main.py                # å¯åŠ¨å…¥å£
â”œâ”€â”€ config.py              # å®šä¹‰ App åŠæ³¨å†Œä»»åŠ¡
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sam_med3d/         # æ¨¡å‹æ–‡ä»¶å¤¹ï¼Œä¿å­˜ weightsã€configã€log
â”‚
â”œâ”€â”€ infer/
â”‚   â””â”€â”€ sam_med3d.py       # è‡ªå®šä¹‰æ¨ç†ä»»åŠ¡ç±»ï¼Œç»§æ‰¿ BasicInferTask
â”‚
â”œâ”€â”€ train/                 # å¯é€‰ï¼šè®­ç»ƒå™¨å®šä¹‰
â”œâ”€â”€ score/                 # å¯é€‰ï¼šæ‰“åˆ†å™¨å®šä¹‰
â”œâ”€â”€ strategy/              # å¯é€‰ï¼šä¸»åŠ¨å­¦ä¹ ç­–ç•¥
â””â”€â”€ transforms/            # è‡ªå®šä¹‰ transformsï¼ˆå¦‚ RAS æ–¹å‘å¤„ç†ã€åæ ‡è¡¥å¿ç­‰ï¼‰
```

---

## ğŸš€ ä¸€ã€éƒ¨ç½²ä¸è¿è¡Œå…¥å£ï¼ˆ`main.py` + `config.py`ï¼‰

### âœ¨ `main.py`

```python
from monailabel.interfaces.app import main
from config import SAMMed3DApp

if __name__ == "__main__":
    main(SAMMed3DApp())
```

### âœ¨ `config.py`

```python
from monailabel.interfaces.app import MONAILabelApp
from infer.sam_med3d import SAMMed3DInferTask
import os

class SAMMed3DApp(MONAILabelApp):
    def __init__(self):
        super().__init__(
            app_dir=os.path.dirname(__file__),
            studies=os.path.join(os.path.dirname(__file__), "studies"),
            conf={"preload": "true"},
            name="SAMMed3D App",
            description="Interactive SAM-based segmentation",
        )

    def init_infers(self):
        return {
            "SAMMed3D": SAMMed3DInferTask(
                path=os.path.join(self.models_dir, "sam_med3d"),
                type=InferType.DEEPEDIT,
                labels={"organ": 1, "background": 0},
                spatial_size=(128, 128, 128),
                target_spacing=(1.0, 1.0, 1.0),
                number_intensity_ch=3,
                dimension=3,
                description="SAM + DeepEdit hybrid interactive segmentation"
            )
        }
```

---

## âš™ï¸ äºŒã€è‡ªå®šä¹‰æ¨ç†æ¨¡å—ï¼ˆ`BasicInferTask`ï¼‰

### âœ… å¿…é¡»é‡å†™çš„æ¥å£ï¼š

| æ–¹æ³•å                           | ä½œç”¨                                                                                    |
| ----------------------------- | ------------------------------------------------------------------------------------- |
| `pre_transforms(self, data)`  | è¾“å…¥æ•°æ®é¢„å¤„ç†ã€‚å¿…é¡»ä½¿ç”¨ `AddGuidanceFromPointsDeepEditd` ç­‰ transform ä»¥ä» 3D Slicer guidance ä¸­è§£æå‡ºç‚¹ |
| `post_transforms(self, data)` | æ¨ç†åå¤„ç†ï¼Œå¦‚ softmax/argmax/è¿˜åŸåæ ‡ç­‰                                                          |
| `inferer(self, data)`         | è¿”å›æ¨ç†å™¨å®ä¾‹ï¼Œå¦‚ `SimpleInferer()`ã€`SlidingWindowInferer()`                                  |

### âœ… å»ºè®®é‡å†™çš„æ¥å£ï¼š

| æ–¹æ³•å                                | ä½œç”¨                                           |
| ---------------------------------- | -------------------------------------------- |
| `run_inferer(self, inputs, model)` | æ§åˆ¶æ¨¡å‹å‰å‘ä¼ æ’­é€»è¾‘ï¼ˆå¦‚ SAM prompt æ‹¼æ¥ã€è¡¥å¿åæ ‡ã€æ˜¾å¼ batch æ„é€ ï¼‰ |
| `__init__()`                       | æŒ‡å®šæ¨ç†æ¨¡å‹ã€ç»´åº¦ã€æ ‡ç­¾æ˜ å°„ã€æè¿°ç­‰å‚æ•°                         |
| `run()`                            | ä¸å»ºè®®é‡å†™ï¼Œé™¤éå®Œå…¨è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘                            |
| `work()`                           | ç”¨äºé•¿æœŸè¿è¡Œåå°æ¨ç†ä»»åŠ¡ï¼Œä¾‹å¦‚å®æ—¶æ ‡æ³¨ã€ç‚¹æ‰©å±•ç­‰                     |

---

## ğŸ§© ä¸‰ã€æ¨ç†æµç¨‹è¯¦è§£

```python
class SAMMed3DInferTask(BasicInferTask):

    def pre_transforms(self, data):
        return [
            LoadImaged(keys="image"),
            EnsureChannelFirstd(keys="image"),
            Orientationd(keys="image", axcodes="RAS"),
            ScaleIntensityRanged(keys="image", a_min=-175, a_max=250, b_min=0.0, b_max=1.0),
            AddGuidanceFromPointsDeepEditd(
                ref_image="image", guidance="guidance", label_names=self.labels
            ),
            ResizeGuidanceMultipleLabelDeepEditd(guidance="guidance", ref_image="image"),
            AddGuidanceSignalDeepEditd(
                keys="image", guidance="guidance", number_intensity_ch=self.number_intensity_ch
            ),
            EnsureTyped(keys="image", device=data.get("device") if data else None),
        ]

    def inferer(self, data=None):
        return SimpleInferer()

    def run_inferer(self, inputs, model):
        logits = model(inputs)  # å¯æ’å…¥è‡ªå®šä¹‰ maskã€prompt ç­‰å¤„ç†
        return logits

    def post_transforms(self, data):
        return [
            EnsureTyped(keys="pred"),
            Activationsd(keys="pred", softmax=True),
            AsDiscreted(keys="pred", argmax=True),
            SqueezeDimd(keys="pred", dim=0),
            ToNumpyd(keys="pred"),
            Restored(keys="pred", ref_image="image", config_labels=self.labels),
            GetCentroidsd(keys="pred", centroids_key="centroids")
        ]
```

---

## ğŸ“ å››ã€guidance ç”¨æˆ·äº¤äº’æ•°æ®å¤„ç†

### 3D Slicer è¯·æ±‚æ ¼å¼ï¼š

```json
{
  "image": "study1/image.nii.gz",
  "guidance": {
    "background": [],
    "organ": [[205, 12, 154], [133, 11, 126]]
  }
}
```

### æ³¨æ„äº‹é¡¹ï¼š

1. åŸå§‹åæ ‡ä¸º `(X, Y, Z)`ï¼Œéœ€è¡¥å¿ crop åç§»ï¼ˆ`meta_info["cropping_params_functional"]`ï¼‰
2. `AddGuidanceFromPointsDeepEditd` ä¼šè‡ªåŠ¨ç”Ÿæˆ `guidance` tensorï¼Œå¯ç”¨äº `AddGuidanceSignalDeepEditd` æ·»åŠ  mask channel
3. å¦‚æœä½¿ç”¨è‡ªå®šä¹‰æ¨ç†æµç¨‹ï¼Œå¯æ‰‹åŠ¨è°ƒç”¨ä»¥ä¸‹æ–¹æ³•è¿›è¡Œè¡¥å¿ï¼š

```python
def compensate_user_points_for_crop(user_points, meta_info):
    d_crop, _, h_crop, _, w_crop, _ = meta_info["cropping_params_functional"]
    crop_offset = torch.tensor([[[w_crop, h_crop, d_crop]]], dtype=torch.float32)
    return user_points - crop_offset
```

---

## ğŸ§ª äº”ã€å¯é€‰æ¨¡å—è¯´æ˜ï¼ˆscore/train/strategyï¼‰

### âœ… `strategy/`ï¼šä¸»åŠ¨å­¦ä¹ ç­–ç•¥æ¨¡å—

* æ¥å£åŸºç±»ï¼š`monailabel.interfaces.tasks.strategy.ActiveLearningStrategy`
* åº”ç”¨åœºæ™¯ï¼šè‡ªåŠ¨é€‰æ‹©æœ€æœ‰ä¿¡æ¯é‡çš„æ•°æ®ç”¨äºäººå·¥æ ‡æ³¨ï¼ˆå¦‚ uncertainty, random ç­‰ï¼‰
* å¯ç”¨åå°†ä½œç”¨äº `/activelearning/next_sample`

### âœ… `train/`ï¼šè®­ç»ƒä»»åŠ¡æ¨¡å—

* æ¥å£åŸºç±»ï¼š`monailabel.interfaces.tasks.train.TrainTask`
* è‡ªå®šä¹‰è®­ç»ƒå™¨ï¼Œç”¨äº `/train` æ¥å£è¿›è¡Œå¢é‡å­¦ä¹ æˆ–å¾®è°ƒ
* å¯é›†æˆ TensorBoardã€Ampã€DALI ç­‰é«˜çº§åŠŸèƒ½

### âœ… `score/`ï¼šè¯„ä¼°ä»»åŠ¡æ¨¡å—

* æ¥å£åŸºç±»ï¼š`monailabel.interfaces.tasks.scoring.ScoringMethod`
* ç”¨äºè¯„åˆ†æ¨¡å‹æ€§èƒ½æˆ–æ ·æœ¬è´¨é‡ï¼ˆç”¨äºä¸»åŠ¨å­¦ä¹ é€‰æ‹©ã€æ•°æ®åˆ†æç­‰ï¼‰

---

## ğŸ“¦ å…­ã€TaskConfig å¯é€‰å°è£…ï¼ˆè¿›é˜¶ï¼‰

è™½ç„¶å¤§å¤šæ•°é¡¹ç›®ä¸ä½¿ç”¨ï¼Œä½† `TaskConfig` å¯ç”¨äºé›†ä¸­å¼å‚æ•°é…ç½®ï¼Œä¸»è¦åŒ…å«ï¼š

* æ¨¡å‹ç»“æ„å®šä¹‰
* transforms æ³¨å†Œ
* loss å‡½æ•°ä¸ä¼˜åŒ–å™¨ç»Ÿä¸€ç®¡ç†

```python
from monailabel.interfaces.config import TaskConfig

class MyTaskConfig(TaskConfig):
    def __init__(self):
        super().__init__()
        self.network = UNet(...)
        self.transforms_train = Compose([...])
        self.loss_function = DiceCELoss()
```

---


